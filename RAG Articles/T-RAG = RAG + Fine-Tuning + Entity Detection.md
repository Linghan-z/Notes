# Medium博客：T-RAG = RAG + Fine-Tuning + Entity Detection

> T-RAG方法基于将RAG架构与开源的经过优化的LLM和实体树向量数据库相结合。
>
> 上下文检索。
>
> Author: [Cobus Greyling](https://cobusgreyling.medium.com/?source=post_page-----9a5aaa01e437--------------------------------)
>
> URL: https://cobusgreyling.medium.com/t-rag-rag-fine-tuning-entity-detection-9a5aaa01e437

## Introduction

这项研究分享了在私人文件上部署LLM问答应用的经验，使用了一个名为Tree-RAG（T-RAG）的系统，该系统整合了实体层次结构以提高性能。

## Data Privacy

- 由于私人文档的敏感性，安全风险是一个主要问题，这使得使用专有的LLM模型而不是公共API来避免数据泄漏风险。这需要**使用可以在本地部署的开源模型**

- 此外，**有限的计算资源和基于现有文档的较小训练数据**集带来了挑战。

## Take_Aways

将检索-增强生成(RAG)与微调的开源大型语言模型(LLM)集成在一起，以生成回答。该模型使用从组织文件中派生的指令数据集进行训练。

新的评价指标：

- ==**Correct-Verbose**==： 评估生成的回答的质量。该指标根据回答的正确性进行评估，同时考虑了超出原始问题范围的额外相关信息的包含

## T-RAG

对于给定的用户查询，向量数据库会搜索相关的文档块，该块作为LLM上下文学习的参考。

如果查询涉及到任何组织相关的实体，将从实体树中提取有关实体的信息并添加到上下文中。经过微调的Llama-2 7B模型根据提供的数据生成回答。



<img src="./assets/CleanShot 2024-02-26 at 16.49.54@2x.png" alt="CleanShot 2024-02-26 at 16.49.54@2x" style="zoom:50%;" />

T-RAG的一个特点是除了矢量数据库外，还包括实体树以用于上下文检索。

## Entities Tree

T-RAG的一个独特之处是在向量数据库旁边加入了一个实体树，用于上下文检索。实体树存储了组织实体及其层次结构的详细信息。树中的每个节点代表一个实体，父节点表示它们所属的组。

在检索过程中，此框架利用实体树来增强从向量数据库中检索到的上下文。

实体树搜索和上下文生成的过程如下：

1. 最初，解析器模块（parser module）会扫描用户查询中与组织内实体名称对应的**关键词**。
2. 在识别到一个或多个匹配项后，将从树中提取每个匹配实体的**详细信息**。
3. **这些细节被转化为文本陈述**，提供有关实体及其在组织层级中的位置的信息。
4. 随后，将==**从向量数据库中检索到的文档块与这些信息合并，以构建上下文**==。
5. 通过采用这种方法，当用户查询时，**模型可以获得有关实体及其在组织中的层次位置的相关信息**。

<img src="./assets/CleanShot 2024-02-27 at 21.49.16@2x.png" alt="CleanShot 2024-02-27 at 21.49.16@2x" style="zoom: 50%;" />

>  考虑上面的图像，上下文生成的检索过程涉及利用组织结构图中的一个说明性示例来展示如何执行树搜索和检索。

除了获取上下文文档外，还使用 spaCy 库和自定义规则来识别组织内的命名实体。

如果查询包含一个或多个这样的实体，则从树中提取有关实体层次位置的相关信息，并将其转换为文本语句。然后，这些语句与检索到的文档一起合并到上下文中。

然而，如果用户的查询没有提及任何实体，则树搜索将被省略，只利用从检索到的文档中获取的上下文。

## In Conclusion

这项研究很有趣，因为它结合了RAG和微调。在利用托管在本地的开源模型解决数据隐私问题的同时，同时解决推理延迟、令牌使用成本以及区域和地理可用性等问题。

通过spaCy框架使用实体进行实体搜索和上下文生成也很有趣。这不仅是一篇研究文章，而且基于构建用于现实世界应用的LLM应用程序的经验教训。

# Article：T-RAG: LESSONS FROM THE LLM TRENCHES

















