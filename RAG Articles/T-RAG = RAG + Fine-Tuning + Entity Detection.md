# Medium博客：T-RAG = RAG + Fine-Tuning + Entity Detection

> T-RAG方法基于将RAG架构与开源的经过优化的LLM和实体树向量数据库相结合。
>
> 上下文检索。
>
> Author: [Cobus Greyling](https://cobusgreyling.medium.com/?source=post_page-----9a5aaa01e437--------------------------------)
>
> URL: https://cobusgreyling.medium.com/t-rag-rag-fine-tuning-entity-detection-9a5aaa01e437

## Introduction

这项研究分享了在私人文件上部署LLM问答应用的经验，使用了一个名为Tree-RAG（T-RAG）的系统，该系统整合了实体层次结构以提高性能。

## Data Privacy

- 由于私人文档的敏感性，安全风险是一个主要问题，这使得使用专有的LLM模型而不是公共API来避免数据泄漏风险。这需要**使用可以在本地部署的开源模型**

- 此外，**有限的计算资源和基于现有文档的较小训练数据**集带来了挑战。

## Take_Aways

将检索-增强生成(RAG)与微调的开源大型语言模型(LLM)集成在一起，以生成回答。该模型使用从组织文件中派生的指令数据集进行训练。

新的评价指标：

- ==**Correct-Verbose**==： 评估生成的回答的质量。该指标根据回答的正确性进行评估，同时考虑了超出原始问题范围的额外相关信息的包含

## T-RAG

对于给定的用户查询，向量数据库会搜索相关的文档块，该块作为LLM上下文学习的参考。

如果查询涉及到任何组织相关的实体，将从实体树中提取有关实体的信息并添加到上下文中。经过微调的Llama-2 7B模型根据提供的数据生成回答。



<img src="./assets/CleanShot 2024-02-26 at 16.49.54@2x.png" alt="CleanShot 2024-02-26 at 16.49.54@2x" style="zoom:50%;" />

T-RAG的一个特点是除了矢量数据库外，还包括实体树以用于上下文检索。

## Entities Tree

T-RAG的一个独特之处是在向量数据库旁边加入了一个实体树，用于上下文检索。实体树存储了组织实体及其层次结构的详细信息。树中的每个节点代表一个实体，父节点表示它们所属的组。

在检索过程中，此框架利用实体树来增强从向量数据库中检索到的上下文。

实体树搜索和上下文生成的过程如下：

1. 最初，解析器模块（parser module）会扫描用户查询中与组织内实体名称对应的**关键词**。
2. 在识别到一个或多个匹配项后，将从树中提取每个匹配实体的**详细信息**。
3. **这些细节被转化为文本陈述**，提供有关实体及其在组织层级中的位置的信息。
4. 随后，将==**从向量数据库中检索到的文档块与这些信息合并，以构建上下文**==。
5. 通过采用这种方法，当用户查询时，**模型可以获得有关实体及其在组织中的层次位置的相关信息**。

<img src="./assets/CleanShot 2024-02-27 at 21.49.16@2x.png" alt="CleanShot 2024-02-27 at 21.49.16@2x" style="zoom: 50%;" />

>  考虑上面的图像，上下文生成的检索过程涉及利用组织结构图中的一个说明性示例来展示如何执行树搜索和检索。

除了获取上下文文档外，还使用 spaCy 库和自定义规则来识别组织内的命名实体。

如果查询包含一个或多个这样的实体，则从树中提取有关实体层次位置的相关信息，并将其转换为文本语句。然后，这些语句与检索到的文档一起合并到上下文中。

然而，如果用户的查询没有提及任何实体，则树搜索将被省略，只利用从检索到的文档中获取的上下文。

## In Conclusion

这项研究很有趣，因为它结合了RAG和微调。在利用托管在本地的开源模型解决数据隐私问题的同时，同时解决推理延迟、令牌使用成本以及区域和地理可用性等问题。

通过spaCy框架使用实体进行实体搜索和上下文生成也很有趣。这不仅是一篇研究文章，而且基于构建用于现实世界应用的LLM应用程序的经验教训。

----

# Article：T-RAG: LESSONS FROM THE LLM TRENCHES

一个重要的应用领域是在私人企业文件上进行问答，主要考虑因素是**数据安全**，这需要可以部署在本地的应用程序、有限的计算资源以及对查询正确响应的强大应用。

虽然构建一个RAG相对简单，但要使其稳健且可靠的应用程序需要进行广泛定制，并具有相对深入的应用领域知识。

==**Tree-RAG (T-RAG)**==

- 本文的方法结合了RAG的使用和经过微调的开源LLM。
- 使用树结构来表示组织内实体层次结构
  - 这用于生成文本描述，以增强在回答与组织层级内实体相关的用户查询时的上下文。

## 1 Introduction

LLM对专有组织文件（如治理/政策手册）的问答

- 这些文件通常是一个常规参考点，因为它们指导组织内的日常运营和决策制定。
- 这导致经常参考此类文件或组织内的专家，以回答有关此类信息的查询。
- 拥有一个可以根据组织文件回应各种用户查询的应用程序会提高效率。

- consideration
  - 鉴于这些文件的机密性质，存在安全风险，由于数据泄漏风险，无法通过API使用专有的LLM模型。这需要使用可以部署在本地的开源模型。
  - 有限的计算资源以及相对较小的训练数据集，这些数据集可以根据可用文档生成。
  - 任何这类应用程序必须能够可靠且正确地响应

> Use Case：
>
> 我们的使用案例是基于组织治理手册进行问答。这类文件的主要特点包括（i）描述组织的治理原则、各种管理机构的职责和责任；（ii）关于组织下属实体完整层次结构及其分类的详细信息。
>
> 一个基于文档回答问题的LLM应用程序应该能够回答一系列问题，比如描述各种管理机构及其职责，以及列出组织内部实体和它们所属的类别。以下是一些说明性示例，展示了用户可能根据关于联合国组织的文件提出的查询类型：
>
> - How does Giga plan to involve UNICEF and ITU counterparts in their strategy?
>   - Giga计划如何将联合国儿童基金会和国际电信联盟的同行纳入他们的战略中？
>   - （Giga是联合国儿童基金会（UNICEF）和国际电信联盟（ITU）发起的一个倡议，旨在将每所学校连接到互联网。ITU是国际电信联盟。）
> - Give examples of entities under HR Management?
> - Who are the three broad categories of audiences that Giga will target in 2023?

在这项工作中，我们分享了构建和部署一个用于问题回答的LLM应用程序的经验，该应用程序针对一家大型非营利组织的私人治理手册文档。我们做出以下贡献：

- 我们提供了一个真实案例研究，展示如何为组织的最终用户创建一个由LLM驱动的问答应用程序，用于对治理文件进行问答。
- 我们创建了一个应用程序，将检索增强生成（RAG）与经过微调的开源LLM结合起来，用于响应生成，在组织文档生成的指令数据集上进行训练。
- 我们在系统中包含了一种新颖的基于树的上下文作为一个组件，我们称之为Tree-RAG（T-RAG）。它使用树结构来表示层次信息，即组织中的实体。这用于生成文本描述以增强上下文，在回答与组织层次结构内实体相关的用户查询时。
- 我们提出了一种新的评估指标（Correct-Verbose），用于评估生成的回复。该指标捕获了正确的回复，同时还提供了与问题无关的额外正确信息。

## 2 Related Work

### 2.1 Large Language Models

### 2.2 Finetuning

### 2.3 Retrieval-Augmented Generation (RAG)

RAG 对用于创建上下文的检索文档的组成很敏感，因此需要进行大量定制工作，以构建一个有效的检索流程。

### 2.4 Knowledge Graphs

- 基于用户查询中提到的实体，可以从知识图谱中提取相关信息，并作为上下文以
  - 三元组的原始格式提供。[Baek et al.(2023)]
  - 改写为文本陈述[Wu等人(2023年)]

### 2.5 Applications of LLMs

## 3 Relevant Terminology

- Prompt
- System Prompt
- Context
- In-context Learning
- Context Window/Length
- Hallucination

## 4 Retrieval-Augmented Generation

**Algorithm 1**：提供了典型的RAG应用概述

<img src="./assets/CleanShot 2024-02-28 at 11.18.31@2x.png" alt="CleanShot 2024-02-28 at 11.18.31@2x" style="zoom:40%;" />

包含两个过程：

- Index：在应用程序启动时进行一次索引处理
  - 输入文档D被分割成离散的块{c1，c2，...，cn}(步骤2和3)。
  - 使用编码器encoder模型，将分割块 ci 转换为嵌入向量di = encoder(ci)（步骤 4）
  - 存储在向量数据库中（步骤 5），该数据库随后用于检索给定查询的相关块。
- Query：查询过程针对传入查询每次发生的
  - 对于给定的查询 q，编码模型用于创建查询向量嵌入 queryv⃗ = encoder(q)。
  - 然后搜索数据库，找到与查询嵌入向量v⃗相似的前k个块嵌入{ ⃗d1, ⃗d2, ..., ⃗dk}。
  - 确定块嵌入di与查询嵌入v⃗之间的相似性以及要获取多少个和哪些块的各种算法。
  - 从数据库中检索到的前 k 个块 {c1, c2, ..., ck}，连同查询一起传递到提示模板中。
  - 然后将完成的提示输入到LLM模型中，该模型根据提供的信息生成输出。然后将此响应返回给用户。

### 4.1 T-RAG

**Algorithm 2**：Tree-RAG

<img src="./assets/CleanShot 2024-02-28 at 12.42.54@2x.png" alt="CleanShot 2024-02-28 at 12.42.54@2x" style="zoom:40%;" />

Workflow of Tree-RAG (T-RAG)：

- 对于给定的用户查询，我们搜索向量数据库以查找相关的文档片段用作上下文。
- 此外，如果查询提及组织中的实体，则会从实体树中提取有关它们的信息，并添加到上下文中。
- 在组织文档生成的指令数据集上对Llama-2 7B模型进行了微调。
- 使用微调后的模型进行响应生成。

<img src="./assets/CleanShot 2024-02-28 at 12.43.49@2x.png" alt="CleanShot 2024-02-28 at 12.43.49@2x" style="zoom:50%;" />

在查询过程中与典型的RAG应用程序不同

- 不使用现有的预训练LLM，而是使用经微调的LLM进行答案生成
- 基于组织文件生成的问题和答案数据集上对LLM模型进行了微调

T-RAG的一个特点是除了==矢量数据库  vector database==外，还包括==实体树  entities tree==以用于上下文检索。

==**实体树**==：实体树保存了组织中实体的信息以及它们在层次结构中的位置。该树中的每个节点代表一个实体，父节点表示其所属的组。

在检索过程中，我们使用实体树来进一步增强向量数据库检索到的上下文。

实体树搜索和上下文生成如下所示：

- 一个解析器模块会搜索用户查询，查找与组织实体名称匹配的关键词
- 如果找到一个或多个匹配项，则从树中提取每个匹配实体的信息，并将其转换为文本语句，提供有关该实体及其在组织层次结构内位置的信息
- 然后将这些信息与从向量数据库中检索到的文档块结合起来，形成上下文。
- 这使得模型能够在用户询问有关这些实体的问题时访问有关实体及其在组织层次结构中的位置的信息。

## 5 Methods

### 5.1 Instruction Dataset Preparation 指令数据集的准备

>  从组织文档中生成一份指导数据集

1. 第一步==**（pdf->text）**==是将原始PDF文档文件解析为文本格式以供进一步处理，使用LangChain库
   - 除了文本之外，该文件还包含了几个表格和一幅图像，展示了组织结构图中的所有实体——人工处理
2. 第二步是将文档分块==**（text->chunk）**== 这是根据文档中的章节标题完成的，将每个部分拆分为单独的块
3. 第三步==**(question, answer) pairs**==通过多次迭代为每个块生成了（问题，答案）对
   - 在第一次迭代中，对于每个块，我们使用Llama-2模型为提供的块生成问题和答案，该模型被要求生成各种问题类型，如真假题、摘要、简答等。
   - 在第二次迭代中，对于每个块，模型被提示一个对话示例，并要求生成用户和AI助手之间的对话。
   - 在第三次迭代中，模型被要求执行相同的任务（为给定的块生成问题和答案）;在这个迭代中，模型提供了由人类专家根据文档创建的问题示例。

我们汇总了各个迭代生成的问题和答案，以创建我们的数据集。通过手动检查生成的问题和答案来进行质量检查。我们还执行了重复项删除操作，以去除任何重复的问题。我们的数据集包括1,614对问题和答案，随机分为90%训练集和10%验证集。

### 5.2 LLM finetuning

QLoRA

> QLoRA 通过权重量化实现了显著的内存节省，其中模型权重 W0 被减少到更低精度的 4 位表示。
>
> 
>
> 设置r=64

### 5.3 Tree Graph for Entities

- 文档中有个组织结构图，展示了组织内的层级和分工。其中包括了组织下所有实体的清单，以及它们所属的具体类别和子类别

- 组织层次结构及其中的所有实体都以树形编码，其中每个节点代表组织中的某个实体

- 每个节点的父级表示它所属的直接类别
- 通过这种方式，树对组织内每个实体的完整层次结构进行编码，并可用于追踪从实体到其所属更高级别类别以及可能归入其中的其他实体的完整路径
- 此信息可以**在检索步骤中提取并转换为文本语句**
- 这些语句随后被**包含在上下文中**，除了从向量数据库检索到的文档块之外
- 通过提供与实体相关的信息，增强了上下文，这些信息可以被LLM模型用于生成响应                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        

<img src="./assets/CleanShot 2024-02-28 at 13.40.53@2x.png" alt="CleanShot 2024-02-28 at 13.40.53@2x" style="zoom:33%;" />

> - 除了检索上下文文档外，还使用spaCy库和自定义规则来检测组织的命名实体。如果查询包含一个或多个这样的实体，则从树中检索有关该实体在层次结构中位置的信息，并将其格式化为文本语句；
>
> - 然后将这些语句添加到上下文中，以补充已检索到的文档。
> - 如果用户的查询中没有提到的实体，则跳过树搜索，仅使用检索文档中的上下文。

- 需要检测用户查询中是否提到组织的实体以及具体是哪些
  - 如果用户的查询没有提及组织中的任何实体，则跳过树搜索，仅使用检索到的文档中的上下文
  - 为了实现这种自适应行为，我们需要一种检测与组织相关的命名实体的方法。
  - 我们使用了spaCy库来检测和提取用户查询中的命名实体。
    - 为用例定制库，方法是定义一个新类别，其中包含使用字符串匹配检测属于组织的实体的规则。

整体的流程：

- 用户输入查询
- 从向量库中进行文档检索，识别相关的信息块作为上下文（基础的RAG）
- 识别用户的查询Query中的命名实体
  - 如果识别不到就跳过实体树的部分
  - 如果识别到了就从树中抽取信息，并将信息转换为文本形式，和之前的文档块一同作为上下文

### 5.4 Implementation configurations

#### 5.4.1 LLM Model for Answer Generation

本地部署 Llama-2

#### 5.4.2 System Implementations

<img src="./assets/CleanShot 2024-02-28 at 15.29.41@2x.png" alt="CleanShot 2024-02-28 at 15.29.41@2x" style="zoom:33%;" />

1. Llama-2 使用原始文档中的块生成答案

2. 微调Llama-2

3. T-RAG：结合了使用RAG检索相关上下文和使用微调模型生成响应，上下文信息有两个来源：

   1. 普通RAG检索的chunk

      - 我们使用[Chroma DB](https://www.trychroma.com/)向量数据库来存储文档块，以进行上下文检索。
      - 我们在检索过程中使用了最大边际相关性（MMR）进行文档选择；该算法根据与输入查询的相似度以及优化检索文档的多样性来选择文档。
      - 嵌入模型，“Instructor”是一个文本嵌入模型，可以为各种领域生成嵌入向量==**[Su et al.(2023)]One Embedder, Any Task: Instruction-Finetuned Text Embeddings**==。

   2. entity Tree中检索的实体

   3. 在推断过程中，我们使用贪婪解码（温度为0），并设置重复惩罚系数（repetition penalty）为1.1 以生成响应。

      > ==Repetition Penalty==
      >
      > url:https://zhuanlan.zhihu.com/p/659961396
      >
      > **重复性惩罚方法通过在模型推理过程中加入重复惩罚因子，对原有softmax结果进行修正，降低重复生成的token被选中的概率【4】**。以下公式为例，其中T代表温度，温度越高，生成的句子随机性越强，模型效果越不显著；I就代表惩罚项，c代表我们保存的一个list，一般为1-gram之前出现过的单词，**theta值一般设置为1.2，1.0代表没有惩罚**。
      >
      > <img src="./assets/CleanShot 2024-02-28 at 15.21.21@2x.png" alt="CleanShot 2024-02-28 at 15.21.21@2x" style="zoom:33%;" />
      >
      > 重复性惩罚方法是一种简单有效的重复抑制手段，因为它通过提高I值，有效降低集合c中词再次被选中的概率。当然，类似与unlikelihood training，**本方法也可以通过设置不同的c集合来改变惩罚的方向**。（该方法仅能解决1.1节中阐述的前两种重复问题，无法解决输入多次相同prompt输出单调性的问题）
      >
      > 论文地址：[https://arxiv.org/pdf/1909.05858.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1909.05858.pdf)
      >
      > 
      >
      > **Huggingface中，model.generate已经包含此参数，仅需设置repetition_penalty=p（p>1.0）即可开启重复惩罚因子**

## 6 Results

### 6.1 Performance Evaluation

- 自动评估：基于强大的大模型入GPT-4或者是为评估任务微调过的专门用于评估的LLM
- 人工评估

---

本系统使用人工评估

- 该系统经历了三轮与组织内最终用户的测试，在评估中使用了三套问题
  - 第一套问题集由熟悉文档的组织内专家策划，并用于系统的初步测试。
  - 第二和第三套问题集是在组织其他最终用户进行额外测试轮次期间生成的。

生成的回答由人类专家评估，该专家将回答标记为：

1. 正确 ==Correct（C）==，如果回答解决了问题并且在事实上是正确的
2. 正确-详细 ==Correct-Verbose（CV）==，如果回答解决了问题但还提供了其他与问题无关但在事实上是正确的信息

结果报告在表3中。所有三组合并后的结果以粗体显示，在“Questions Set”列下标签“All”之下。表格中的列(T)是被判定为“Correct”或“Correct-Verbose”的总响应数目。(N)代表问题数量

<img src="./assets/CleanShot 2024-02-28 at 15.32.31@2x.png" alt="CleanShot 2024-02-28 at 15.32.31@2x" style="zoom:50%;" />

### 6.2 Evaluating The Entity Tree Search Module

我们创建了两组与实体相关的问题。我们将这些测试集命名为

- （i）simple：直接提问有关组织实体的问题
- （ii）complex：包含询问属于某个类别的部分或全部实体的问题，或询问属于两个不同类别的实体的复合问题

<img src="./assets/CleanShot 2024-02-28 at 15.41.52@2x.png" alt="CleanShot 2024-02-28 at 15.41.52@2x" style="zoom:50%;" />

#### 6.2.1 Evaluation on Entities from UNHCR Organizational Chart

询问有关联合国难民署组织层级内各个实体的问题

- 简单问题：6 (46.2%)->12 (92.3%)
- 复杂问题：6 (46.2%)->8 (61.5%)

#### 6.2.2 Qualitative Evaluations

有树形上下文而减少的错误：幻觉 hallucination、回答错误 misaligned answers（提到了实体但是放错类别，事实错误）

### 6.3 Overfitting Test of Finetuned Model 过拟合测试

>  大规模多任务语言理解（MMLU）基准测试 Massive Multitask Language Understanding (MMLU) benchmark [Hendrycks et al.(2021)]
>
> MMLU 用于评估语言理解和知识的LLM，它包括涵盖STEM、人文学科、社会科学等多个主题范围的多项选择题

<img src="./assets/CleanShot 2024-02-28 at 15.56.35@2x.png" alt="CleanShot 2024-02-28 at 15.56.35@2x" style="zoom:50%;" />

## 7 Lessons Learned 经验

在为实际应用构建强大的LLM系统时，需要考虑重要因素和定制化。以下是我们根据经验可以分享的一些教训：

- 虽然构建初始的RAG应用程序很容易，但要使其稳健并非易事，需要领域知识专长（我们利用领域专家的帮助筛选示例问题，这些问题被用于我们的提示中生成指导数据集以进行微调），以及许多设计选择来优化系统的不同组件。
- 微调模型可能对问题的措辞敏感。例如，当询问微调模型提供“所有...的全面列表”与“所有...的列表” （"a comprehensive list of all the..." vs. "a list of all the..."）时，前者的回答包含虚构名称而后者则回答正确。我们观察到这种现象在其他问题措辞变化中，并**假设**训练数据集中措辞差异可能是一个解释原因。
- 通过将信息整合到模型参数中，微调模型可以在LLM的有限上下文窗口上节省空间，从而减少所需的上下文量。
- 在系统开发的不同阶段让最终用户参与测试可以生成反馈，帮助指导开发过程中的一些决策。
- 树提供了一个适当的结构，用于表示组织中实体等层次信息，可以用来增强上下文。我们的评估表明，这有助于使系统在回答关于实体的问题时相当稳健。

### 7.1 RAG vs. Finetuning

RAG：

- 对于较小的应用程序，**RAG** 的计算需求可能仅限于所使用的检索技术。
- 如何对源文档进行分块，嵌入模型和检索算法的选择等。
- 可以动态、频繁地更新知识库
- 可以减少幻觉（提供上下文），但是RAG 在整个流程中也存在许多限制，并且对嘈杂或不完整的上下文非常敏感，导致产生幻觉和不完整的答案 

Finetuning：

- 需要更堵的计算资源

- 努力筛选高质量的训练数据集并调整超参数，微调必须谨慎地进行，因为更新模型的参数可能会*降低其整体语言能力*——测试其过拟合
- 需要准备一个训练数据集并重新训练模型来更新知识（参数）
- 对于不熟悉的输入，仍会有幻觉

根据我们的经验，结合 RAG 和微调的混合方法可能对实际应用有所希望，并值得进一步探索。

### 7.2 Future Work

- 更大的语料库
- 将系统扩展为基于聊天的应用程序
  - 有效处理聊天记录
