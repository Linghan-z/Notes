# Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs

> LLM 学习 KG

**问题：**

1. 能否利用LLMs的知识来<u>*弥补*</u>传统GNNpipline中固有的上下文知识和语义理解不足？
   - LLMs-as-Enhancers：leverages LLMs to <u>*enhance*</u> nodes’ text attributes with their massive knowledge and then <u>*generate predictions through GNNs*</u>.
     - different strategies tailored to different types of models, and better leverage their capabilities within the constraints of these usage limitations.
     - **key insights**：
       - using deep sentence embedding models to generate embeddings for node attributes
       - utilizing LLMs to augment node attributes at the text level
2. LLM除了仅与GNN集成之外，还可以<u>*独立*</u>执行具有显式图结构的预测任务吗？
   - LLMs-as-Predictors：directly employ LLMs as <u>*standalone predictors*</u>.structural and attribute information is present completely through natural languages.
     - what information can assist LLMs in better understanding and utilizing graph structures.
     - **key insights**：
       - 有效，但是inaccurate production & data leakage

主要挑战是如何为图学习任务设计一个与LLM兼容的pipline

## 3. PIPELINES FOR LLMS IN GRAPHS

<img src="./assets/CleanShot 2024-04-15 at 14.38.46@2x.png" alt="CleanShot 2024-04-15 at 14.38.46@2x" style="zoom:50%;" />

### LLMs-as-Enhancers

- 第一二个是feature level，
- 第三个是text-level

<img src="./assets/CleanShot 2024-04-15 at 14.42.26@2x.png" alt="CleanShot 2024-04-15 at 14.42.26@2x" style="zoom:50%;" />

## 4. LLMS AS THE ENHANCERS

数据集：

<img src="./assets/CleanShot 2024-04-15 at 16.43.59@2x.png" alt="CleanShot 2024-04-15 at 16.43.59@2x" style="zoom:50%;" />

### 4.1 Feature-level Enhancement

==LLMs in the pipeline must be embedding-visible.==

- Integration structures: **cascading** structure and **iterative** structure.

<img src="./assets/CleanShot 2024-04-15 at 16.40.25@2x.png" alt="CleanShot 2024-04-15 at 16.40.25@2x" style="zoom:50%;" />

- low-label ratio

<img src="./assets/CleanShot 2024-04-15 at 16.40.46@2x.png" alt="CleanShot 2024-04-15 at 16.40.46@2x" style="zoom:50%;" />

- high-label ratio

<img src="./assets/CleanShot 2024-04-15 at 16.40.59@2x.png" alt="CleanShot 2024-04-15 at 16.40.59@2x" style="zoom:50%;" />

- 大数据集

#### 4.1.1 Node Classification Performance Comparison

- **Observation 1.** Combined with different types of text embeddings, GNNs demonstrate distinct effectiveness. GNN有效
  - GNN与MLP相比
- **Observation 2.** Fine-tune-based LLMs may fail at low labeling rate settings. 标签不足的情况下微调不一定有效
  - 表1 fine-tuned PLM and GLEM都不如TF-IDF
- **Observation 3.** With a simple cascading structure, the combination of deep sentence embedding with GNNs makes a strong baseline. 使用deep sentence embedding和GNN cascade有效
  - including both local sentence embedding models and online sentence embedding models
  - 在deep sentence embedding模型encode之后给GNN，在形成embedding的时候没有考虑结构信息，但是比GIANT（entails a structure-aware self-supervised learning stage）在Ogbn-arxiv的表现好
- **Observation 4.** Simply enlarging the model size of LLMs may not help with the node classification performance. 只增大模型的大小不一定有效

#### 4.1.2 Scalability Investigation

<img src="./assets/CleanShot 2024-04-15 at 17.06.36@2x.png" alt="CleanShot 2024-04-15 at 17.06.36@2x" style="zoom:50%;" />

- **Observation 5.** For integrating structures, <u>*iterative structure introduces massive computation*</u> overhead in the training stage.
- **Observation 6.** In terms of different LLM types, deep sentence embedding models present better efficiency in the training stage.
  - 将基于微调的PLM与深度句子嵌入模型进行比较，我们观察到后者在时间效率上表现显著更好，因为它们不需要微调。
  - 此外，深度句子嵌入模型展示出更好的内存效率，因为它们仅涉及推断阶段而无需存储额外信息如梯度。

### 4.2 Text-level Enhancement

==embedding-invisible LLMs to do text-level enhancement==

<img src="./assets/CleanShot 2024-04-16 at 10.11.59@2x.png" alt="CleanShot 2024-04-16 at 10.11.59@2x" style="zoom:50%;" />

1. TAPE [22]:

   1. LLMs to generate high-quality node features
   2. 用PLM来finetune原始文本和增强的文本
   3. 基于原始文本属性和增强文本属性生成相应的文本特征和增强文本特征，最后将它们集成在一起作为GNNs的初始节点特征

   - <img src="./assets/CleanShot 2024-04-16 at 10.26.44@2x.png" alt="CleanShot 2024-04-16 at 10.26.44@2x" style="zoom:50%;" />
     - “TA” refers to “text attributes”, “P” refers to “pseudo labels”, and “E” refers to “explanations”.

   - **Observation 7.** The effectiveness of TAPE is mainly from the explanations E generated by LLMs.
   - **Observation 8.** Replacing fine-tuned PLMs with deep sentence embedding models can further improve the overall performance of TAPE.

2. Knowledge-Enhanced Augmentation(KEA)

   1. enrich the text attributes by providing additional information.

   - <img src="./assets/CleanShot 2024-04-16 at 10.30.17@2x.png" alt="CleanShot 2024-04-16 at 10.30.17@2x" style="zoom:50%;" />
   - <img src="./assets/CleanShot 2024-04-16 at 10.36.18@2x.png" alt="CleanShot 2024-04-16 at 10.36.18@2x" style="zoom:50%;" />
     - “KEA-I”:augmented textual attributes into the original attribute
     - “KEA-S”:encode the augmented attributes and original attributes separately

   - **Observation 9.** The proposed knowledge enhancement attributes KEA can enhance the performance of the original attribute TA.
   - **Observation 10.** For different datasets, the most effective enhancement methods may vary.

## 5. LLMS AS THE PREDICTORS

在LLMs-as-Enhancers中，只利用了LLM的预训练的知识，但是<u>*忽略了其推理能力*</u>

### 5.1 How Can LLM Perform on Popular Graph Benchmarks without Structural Information?

treat the node classification problem as a text classification problem by ignoring the structural information.

- **Observation 11.** LLMs present preliminary effectiveness on some datasets.
  - <img src="./assets/CleanShot 2024-04-16 at 10.37.24@2x.png" alt="CleanShot 2024-04-16 at 10.37.24@2x" style="zoom:50%;" />
- **Observation 12.** Wrong predictions made by LLMs are sometimes also reasonable.
  - <img src="./assets/CleanShot 2024-04-16 at 10.38.33@2x.png" alt="CleanShot 2024-04-16 at 10.38.33@2x" style="zoom:50%;" />
- **Observation 13.** Chain-of-thoughts do not bring in performance gain.
  - <img src="./assets/CleanShot 2024-04-16 at 10.39.40@2x.png" alt="CleanShot 2024-04-16 at 10.39.40@2x" style="zoom:50%;" />
  - not effective for the node classification task

- **Observation 14.** For prompts that are very similar in semantics, there may be huge differences in their effects
  - <img src="./assets/CleanShot 2024-04-16 at 10.42.06@2x.png" alt="CleanShot 2024-04-16 at 10.42.06@2x" style="zoom:50%;" />
    - Strategy 1: the original Arxiv identifier, such as ”arxiv cs.CV”;
    - Strategy 2: natural language descriptors, like ”computer vision”; 
    - Strategy 3: the specialized prompt, utilizing ”arxiv cs subcategory” to denote all categories.

### 5.2 Incorporating Structural Information in the Prompts

- **Observation 15.** Neighborhood summarization is likely to achieve performance gain.

<img src="./assets/CleanShot 2024-04-16 at 10.47.55@2x.png" alt="CleanShot 2024-04-16 at 10.47.55@2x" style="zoom:50%;" />

- **Observation 16.** LLMs with structure prompts may suffer from heterophilous neighboring nodes.
  - 表14 LLMs perform worse on Pubmed after incorporating the structural information.
  - <u>*2 hop nodes have different labels against this node.*</u>

### 5.3 Case Study: LLMs as the Pseudo Annotators

- **Observation 17.** The quality of pseudo labels is key to downstream performance.
- **Observation 18.** Getting the confidence by simply prompting the LLMs may not work since they are too “confident”.
  - <img src="./assets/CleanShot 2024-04-16 at 10.54.32@2x.png" alt="CleanShot 2024-04-16 at 10.54.32@2x" style="zoom:50%;" />
    - achieve the confidence level of LLMs’ outputs.
    - However, we discover that most of the time, LLMs simply output a value of 1, rendering it meaningless.

### 5.4 Case Study: Applying LLMs to handle out-of-distribution data

<img src="./assets/CleanShot 2024-04-16 at 11.31.21@2x.png" alt="CleanShot 2024-04-16 at 11.31.21@2x" style="zoom:50%;" />

- **Observation 19.** LLMs-as-Predictors demonstrate robustness when facing OOD data.

## 7. CONCLUSIONS, LIMITATIONS, AND FUTURE DIRECTIONS

### 7.1 Key Findings

- **Finding 1.** For LLMs-as-Enhancers, **deep sentence embedding models** present effectiveness in terms of performance and efficiency.
- **Finding 2.** For LLMs-as-Enhancers, the combination of LLMs’ augmentations and ensembling demonstrates its effectiveness. **LLMs的增强和集成的组合**
- **Finding 3.** For LLMs-as-Predictors, LLMs present **preliminary** effectiveness but also indicate potential evaluation problem.
  - LLMs’ inaccurate predictions can also be considered reasonable
  - data leakage

### 7.2 Limitations

- A deeper understanding of the effectiveness of text embeddings.
- Costs of LLM augmentations.
- Text-formatted hand-crafted prompts to represent graphs.

### 7.3 Future Directions

- Extending the current pipelines to more tasks and more types of graphs.
- Using LLMs more efficiently
- Evaluating LLMs’ capability for graph learning tasks.
- **Aligning the feature space of graph models and LLMs.**
  - LLMs的特征空间与图的特征空间之间的差异
    - approaches：
      - **translate** the information on the graph into natural language that LLMs can understand.
        - limitation：<u>*information loss*</u>、<u>*input length limitation*</u>
      - directly inputting the graph information in the form of **embeddings** and then using **instruction tuning** to enable LLMs to understand this information.
        - limitation：额外的计算开销
    - 一个多模态的模型的方法：
      - 只用了一个线性变换层，就convert information from the visual domain into content that can be effectively processed by LLMs
