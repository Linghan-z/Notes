## P2

**Zero-Shot Information Extraction via Chatting with ChatGPT**

三个任务：

- 命名实体识别 named entity recognition (NER)
- 实体关系三元组提取 entity-relation triple extract (RE)
- 事件抽取 event extraction (EE)

> 想法其实很简单，就是先分析类型，再根据类型抽取相应的信息

**第一阶段**：目标是分别在三个任务中找出句子中的实体、关系或事件**的类型**

- 筛选掉不存在的元素类型，以减少搜索空间和计算复杂度，有助于提取信息
- 首先利用**特定任务的模板**TypeQuesTemplates和**元素类型列表来构建问题**
- 将问题和句子结合作为输入传递给ChatGPT
- 为了方便提取答案，我们要求LLMs以列表形式回复
- 如果句子中不包含任何元素类型，则返回NONE

**第二阶段**：根据第一阶段提取的元素类型以及相应的任务特定方案**进一步提取相关信息**

- 这个阶段通常包括多个问答环节。
- 针对元素类型设计了一系列特定的ChainExtractionTemplates。
  - 定义了一系列模板链，链的长度通常为1
  - 但对于复杂的方案，例如在实体关系三元组提取中进行复杂对象值提取，链的长度大于一。
  - 在这一点上，元素的提取可能取决于另一个先前的元素，因此我们称之为链式模板。
- 我们**按照先前提取的元素类型和信息的抽取模板**ChainExtractionTemplates的顺序**进行问答**。
- 生成问题时，我们需要检索带有元素类型的模板，并在必要时填充相应的插槽。
- 然后通过ChatGPT来生成相应
- 最后，我们根据每个回合中提取的元素组成结构化信息。

**NER:**

- 第一阶段是根据所需类型列表过滤出句子中的现有实体类型。
- 第二阶段，每一轮的目标是提取一种类型的实体。

因此，第二阶段的轮次取决于第一阶段获得的实体数量，如果第一阶段没有获取到任何类型，则省略第二阶段。

**RE:**生成三元组

- 第一阶段使用根据关系类型列表R和相应模板生成的问题q1以及语句x抽取关系r
- 第二阶段使用第一阶段的抽取的关系r以及相应的模板生成的问题抽取头尾实体

**EE：**

- 第一阶段对给定的文本进行事件分类

- 第二阶段一种抽取式机器阅读理解（MRC）问题，该问题可以从第一阶段预测的事件类型中识别出特定事件的论元

  - **实体（Entity）**：具有特定语义的基本单元，如时间、人物、地点、数量、组织机构等；
  - **事件触发词（Event Trigger）：**标志了某种类型事件发生的词汇
  - **事件类型（Event Type）**：所发生的事件的类别；
  - **事件论元（Event Argument）**：参与事件发生的要素，由实体构成
  - **论元角色（Argument Role）**：事件论元在事件中扮演的角色, 每种事件类型均预定义了多个不同的论元角色域。

---

## P3

实验结果：

1. 这个分阶段的策略，对比单轮的实验结果，尤其是在比较复杂的RE（抽取三元组的任务）效果会好很多
2. 对比一些few-shot 少样本提示的实验结果，可以看到他这个分阶段的零样本的策略的效果比一些few-shot的baseline效果还要好

> 这篇文章比较简单，其实就是一个复杂任务的分解，没有涉及到更进一步的验证等操作

---

## P4

**Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction**

- 提出CooperKGC，使用multi-agent的策略，建立**协作处理网络**同时处理实体、关系和事件提取任务
- 方法可以促进多样化代理之间的**协作和信息交互**，在agent互动中增强彼此的**知识选择、结果修正、结果聚合的能力**

**方法：**

- 采用去中心化的策略，每一个agent处理某个特定的任务，并建立其他的agent的双向沟通机制
- **采用轮次来作为交互的基本单位来完成任务**，并促进专家代理之间的通信
- 复制通信replica communication过程中，我们实施**消息简化**，提取符合模式约束的结果

在协作网络中包含三个主要的组成部分：

1. 专家节点
   1. 在KGC中特定子任务上的代理，输入是前一轮的自己和简化过的别的Agent的输出+原始输入X
   2. Agent可以是：
      - 有指令指导的普通的LLM
      - 加入自我反思机制
      - 外部知识库或利用其他工具的LLM
2. 通信渠道
   1. 前一轮的自己和其他的Agent到这一轮的单向通信
3. 消息处理
   1. 实施**消息简化**，提取符合模式约束的结果
      - 增强信息交换的效率，减少干扰

---

## P5

实验结果

消融实验里面的一些结论：

1. 为专家提供背景知识方面，细粒度模式约束的代理会表现的更好
2. 论次选择不可以过多，看实验效果基本上是二至三轮就好了，过多的论次反而会有幻觉
3. 传递的信息的简化增强了团队内部决策的稳健性，使团队协作更加简洁高效











