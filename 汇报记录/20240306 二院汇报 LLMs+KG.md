## P2 Overview

- 大模型：
  - 隐性知识
  - 幻觉
  - 给出的结果不具备决定性
  - 黑盒
  - 确实领域知识以及新知识
  - 好：
    - 通用知识
    - 语言处理能力
    - 具有泛化能力
- KG
  - 结构性知识
  - 准确
  - 具有决定性
  - 可解释
  - 知识可扩展
  - 不好：
    - 不完备性
    - 缺少自然语言理解
    - 缺少处理未见知识的能力

## P3 知识图谱增强大模型

- 增强大模型的预训练
  - 把KG集成到大模型预训练的训练目标中，**强化对实体的学习**
    - 将预训练的文本输入的实体与KG中的实体对齐
  - KG集成到LLMs预训练的输入中：如KG三元组与文本句子结合，然后用于预训练
  - KG作为额外的融合模块进行处理：KG中的信息被单独处理并融合到LLM中
- 增强大模型的推理
  - 动态融合：使用KG增强输入的文本、使用LLMs输出增强KG的推理
  - RAG：使用KG的检索结果作为LLMs输入的上下文增强LLMs的输出
    - 传统的RAG就分为建立索引、检索以及生成
    - 建立索引就包括：对数据进行清洗与抽取、分块chunking、然后用语言模型将文本编码为向量，用于检索以及计算相似度，生成key-value对用于之后的检索
    - 使用相同的而语言模型对用户的查询编码，然后计算问题与之前的语料的相似度，返回前k个相似度高的chunk用于用户当前的query的上下文
    - 生成就是将问题和检索的上下文给LLMs用于生成答案，这里涉及到对使用的LLMs进行合适的领域微调，以及结合Prompt engineering的一些方法进行针对任务的合适的Prompt的构建
- 增强大模型的可解释性
  - 用于LLMs Probing，理解模型内部知识
  - 用于解释LLMs输出：使用KG定位LLMs推理步骤的中间结果，如左图

## P4 LLMs增强KG

#### 1. 增强图谱嵌入

传统的知识图谱嵌入方法通常只考虑知识图的结构信息。近年来的深度学习方法，使用更深层的神经网络处理实体和关系嵌入进一步考虑结构信息。但这些方法难以解决处理未见实体（unseen entities）和长尾关系（long-tailed relations）的问题。

**LLMs作为encoder：**用基于Bert等模型，这种方式利用LLM对实体和关系的初始输入进行初始编码，然后再使用专用的KGE模型输入这个初始编码，并学习结构信息，从而得到最终的嵌入表示



**LLMs用于联合KG和文本：**将图结构和文本信息合并到嵌入空间中，将实体和实体描述文本，以及关系同时作为token组成一个句子输入LLM。采用将尾实体mask并预测的方法来微调模型，训练的目标是最大化对正确实体的预测。经过训练后的LLM中相应的标记表示被用作相应实体和关系的嵌入

#### 2. 增强图谱补全

作为encoder

作为Sequence2Sequence的生成器，所使用的LLM包括Encoder-Decoder或仅使用Eecoder-only的LLM。LLM接收一个文本序列形式的查询三元组 ( h , r , ? )  ，并直接生成尾部实体t的文本

#### 3. 增强图谱构建

针对特定任务的，比如命名实体识别、指代消解、关系抽取

端到端的图谱构建架构，一般也是由几个小部分组成：

- 比如一个方法是先针对NER任务微调的一个LLM，然后用一个2-model-BERT，抽取关系，两个BERT一个用于识别关系类别一个用于识别关系的方向
- Auto KG：通过Prompt enigineering的方法用GPT完成NER、EL实体链接、RE等步骤，构建图谱

增强KG2text的生成：利用KG中的信息生成高质量文本

增强基于KG的推理：StructGPT 允许大型语言模型（例如ChatGPT）直接在知识图谱上推理，以执行多步问题回答



## P5 Auto KG

针对图谱的构建和推理任务对闭源的大模型进行构建和推理的评估

第一个图是对图谱构建的任务进行的实验的结果，包括命名实体识别、关系事件抽取

第二个图是验证LLMs的对图谱的推理能力，包括链接预测和QA

结果解释：

1. 知识图谱构建任务包括实体、关系、事件等的识别和提取，使其比推理任务更复杂。以链接预测等推理任务主要依靠现有实体和关系进行推理，使任务相对简单
   1. 也可以看出在特定领域方面LLMs表现的更弱，科学领域的Sci那个
2. LLMS在推理任务中的优异表现可能归因于他们在预训练阶段接触到了相关知识。



**关于泛化能力的研究**：大型模型显然擅长从有限的信息中快速提取结构化知识，是由于在预训练阶段利用了大量文本数据，使得模型能够获得相关知识，还是归因于它们强大的推理和泛化能力？

- 构建了虚拟知识抽取的数据集（确保数据集中的实体是LLMs预训练没有接触到的）（实验时是2021年9月，现在GPT4的知识是23年4月）
- 实验结果是GPT-4能够成功抽取80%三元组、ChatGPT只有27% 
- GPT4表现出相对强大的泛化能力，并且可以通过指令快速获取提取新知识的能力，而不仅仅依赖于相关知识的记忆。

**图谱构建和推理**

multi-agent方法：

- AI助手（顾问、协助）和AI用户（领域专家），并且结合了人类专家经验的指导，直接从文本构建图谱



## P6 LLM Powered Autonomous Agents 大模型驱动的自主代理

 大模型驱动的自主代理系统的一个介绍

可以理解为Agent就是利用 LLMs 通过集成不同系统、工具，**自主决策**完成各类复杂任务





**P (plan) 计划**：包括数据收集，方针和目标的确定，以及活动规划的制定。

**D (Do) 执行**：根据设计和布局，进行具体运作，实现计划中的内容。

**C (Check) 检查**：总结执行计划的结果，分清哪些对了，哪些错了，明确效果，找出问题。

**A (Act)处理**：对总结检查的结果进行处理，对成功的经验加以肯定，并予以标准化；对于失败的教训也要总结，引起重视。对于没有解决的问题，应提交给下一个PDCA循环中去解决。



**分三部分来讲，planning、memory、tool use**

- planning主要做两件事情
  - 任务分解，**就是agent将任务分解成更小、可管理的子目标，方便高效处理任务**
    - 任务分解方法
      - 通过简单的prompt使用LLM进行分解
      - 通过使用特定任务的指令
      - 人工输入
    - Cot ToT
    - LLM+P：**利用外部的classical planner 进行长期的规划**。该方法利用规划领域定义语言（Planning Domain Definition Language, PDDL）作为中间接口来描述规划问题。把自然语言转化成PDDL，使用classical planner生成PDDL计划，再将PDDL计划转化为自然语言
  - 反思和完善：**agent对过去的行动进行自我批评和反思，并进行改进，从而提高最终结果的质量**
    - ReAct：ReAct就是Reason+ Act，将行动空间扩展为任务特定的离散行动和语言空间的组合，将推理和行动融合到LLM中，ReAct  prompting的模板是由thought、action和observation这三部分循环组成
    - Reflexion：为agent提供动态记忆dynamic memory和自我反思Self-reflection能力，以提高推理能力。reflexion行动空间是尊存的ReAct的设置。每个动作a_t之后，agent计算一个启发式Heuristic函数h_t，并根据自我反思Self-reflection的结果选择是否重置环境以开始新的试验。
    - CoH 回顾链（Chain of Hindsight, CoH；刘等人，2023年）鼓励模型通过明确呈现一系列过去的输出序列，并附带反馈信息来改进自身的输出。CoH的理念是在上下文中呈现一系列逐步改进的输出历史，并训练模型跟随趋势产生更好的输出。
- **Memory是根据人类的记忆情况，分类成了三种**。
  - Sensory Memory： 感觉记忆， 这是记忆的最早阶段，能够在原始刺激结束后保留感觉信息（视觉、听觉等）的印象。感觉记忆通常只持续几秒钟。子类包括图像记忆（视觉）、回声记忆（听觉）和触觉记忆（触感）。
  - Short-Term Memory (STM) or Working Memory：短期记忆（STM）或工作记忆， 它存储我们目前意识到并需要进行复杂认知任务（如学习和推理）所需的信息。短期记忆被认为具有大约7个项目的容量（米勒，1956年），并持续20-30秒。
  - Long-Term Memory (LTM)：长期记忆，长期记忆可以将信息储存很长时间，从几天到数十年不等，并且具有基本上无限的存储容量。长期记忆有两个子类型：
    - Explicit / declarative memory：外显记忆或陈述记忆，这是关于事实和事件的记忆，指的是那些可以有意识地回忆起来的记忆，包括情景记忆（事件和经历）和语义记忆（事实和概念）。
    - Implicit / procedural memory：内隐记忆或程序记忆，这种类型的记忆是无意识的，涉及到自动执行的技能和例行公事，比如骑自行车或者键盘打字。
  - 我们可以大致考虑以下映射：
    - **感觉记忆作为学习嵌入原始输入的表征，包括文本、图像或其他形式；**
    - **短期记忆就像是上下文学习。它是短暂且有限的，因为它受到Transformer有限上下文窗口长度的限制。**
    - **长期记忆作为外部向量存储，agent可以在查询时关注，并通过快速检索进行访问。**
  - **一个标准记忆的做法是将信息的嵌入表示保存到一个向量存储数据库中** ==RAG==，该数据库可以支持快速的最大内积搜索（MIPS）。为了优化检索速度，常见的选择是使用近似最近邻（ANN）算法
- Tool use
  - Toolformer：通过微调语言模型来学习使用外部工具API。数据集根据新增的API调用注释是否能提高模型输出的质量来进行扩展。
  - HuggingGPT 是一个框架，使用ChatGPT作为任务规划器，根据模型描述选择HuggingFace平台上可用的模型，并根据执行结果总结响应。
  - AutoGPT是一个开源项目，它使用 GPT-4 执行（即模型思考、批评和重新评估任务），并自主尝试实现用户指定的目标。在github已经有145k⭐了
  - BabiAGI本质上是一个与任务列表交互的语言模型，目的是根据预定义的目标自动生成任务、确定任务的优先级和执行任务。